{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlYr+/CEx2wZuff7SXd/YT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RifatMuhtasim/NLP_Natural_Language_Processing/blob/main/Learn/10.Stemming_And_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming and Lemmatization\n",
        "- Stemming and Lemmatization are techniques used to reduce words to their base form or Root Form\n",
        "- Stemming: Using fixed rules such as remove able, ing, etc. to derive the base word.\n",
        "- Lemmatization: Use knowledge of language (Linguistic Knowledge) to derive a base word."
      ],
      "metadata": {
        "id": "FPeVmviVVR7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming Using NLTK"
      ],
      "metadata": {
        "id": "DNLJIwHFcHT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "SS_q0uGscRJT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
        "\n",
        "for word in words:\n",
        "    print(word, \"  |  \", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkPZ6oVVclCx",
        "outputId": "d166aac9-33a3-44b7-de0a-a54848921468"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating   |   eat\n",
            "eats   |   eat\n",
            "eat   |   eat\n",
            "ate   |   ate\n",
            "adjustable   |   adjust\n",
            "rafting   |   raft\n",
            "ability   |   abil\n",
            "meeting   |   meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: Some of the word don't make any sense"
      ],
      "metadata": {
        "id": "a3SpYugndSO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization using Spacy"
      ],
      "metadata": {
        "id": "gAAt4AuedYt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "4aNCNZFVdOld"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"eating eats eat ate adjustable rafting ability meeting\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(f\"{token}  |  {token.lemma_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGPhEk-9dgBW",
        "outputId": "e209d1ae-9620-412e-91bb-3bc21f30faed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eat\n",
            "eats  |  eat\n",
            "eat  |  eat\n",
            "ate  |  eat\n",
            "adjustable  |  adjustable\n",
            "rafting  |  raft\n",
            "ability  |  ability\n",
            "meeting  |  meeting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Customized Root or Base word for Slung Words"
      ],
      "metadata": {
        "id": "Ue4_y_FOeeL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Bro, you wanna go? Brah, don't say no! I am exhausted\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(token, \"  |  \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ-SC0UnfQue",
        "outputId": "ed3b778d-a097-4e84-e189-2e42910bebab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro   |   bro\n",
            ",   |   ,\n",
            "you   |   you\n",
            "wanna   |   wanna\n",
            "go   |   go\n",
            "?   |   ?\n",
            "Brah   |   Brah\n",
            ",   |   ,\n",
            "do   |   do\n",
            "n't   |   not\n",
            "say   |   say\n",
            "no   |   no\n",
            "!   |   !\n",
            "I   |   I\n",
            "am   |   be\n",
            "exhausted   |   exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that some of the slug word like \"Bro\" and \"Brah\" don't return \"brother\" word."
      ],
      "metadata": {
        "id": "8s4DIrtufarx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#customized slug word \"Bro\" and \"Brah\" to \"brother\"\n",
        "ar = nlp.get_pipe(\"attribute_ruler\")\n",
        "ar.add([[{\"TEXT\": \"Bro\"}], [{\"TEXT\": \"Brah\"}]], {\"LEMMA\": \"brother\"})\n",
        "\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(token, \"  |  \", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KZEMpVieJH2",
        "outputId": "75a85310-7776-4482-a91d-c6e6baf3bafc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro   |   brother\n",
            ",   |   ,\n",
            "you   |   you\n",
            "wanna   |   wanna\n",
            "go   |   go\n",
            "?   |   ?\n",
            "Brah   |   brother\n",
            ",   |   ,\n",
            "do   |   do\n",
            "n't   |   not\n",
            "say   |   say\n",
            "no   |   no\n",
            "!   |   !\n",
            "I   |   I\n",
            "am   |   be\n",
            "exhausted   |   exhaust\n"
          ]
        }
      ]
    }
  ]
}